# ğŸŒ‹ Landslide Detection from Satellite Imagery

> **Automated landslide detection using deep learning and multi-spectral satellite imagery**

[![Python 3.12](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.7.1-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

![Landslide Detection Example](docs/images/example_prediction.png)

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Key Features](#-key-features)
- [Dataset](#-dataset)
- [Model Architecture](#-model-architecture)
- [Results](#-results)
- [Installation](#-installation)
- [Usage](#-usage)
- [Project Structure](#-project-structure)
- [Documentation](#-documentation)
- [Citation](#-citation)
- [License](#-license)

---

## ğŸ¯ Overview

This project implements an **Attention U-Net** deep learning model for automatic landslide detection from satellite imagery. The model processes multi-spectral satellite data (Sentinel-2) combined with topographic features (DEM, slope) to identify landslide-affected areas.

### Why This Matters

- ğŸŒ **Early Detection**: Enables rapid identification of landslides across large geographic areas
- ğŸ’° **Cost-Effective**: Automates manual analysis, reducing time and resources
- ğŸ›°ï¸ **Wide Coverage**: Processes satellite data covering vast, inaccessible regions
- ğŸš¨ **Life-Saving**: Early warnings can prevent casualties and property damage

### Challenge

Landslide detection faces several unique challenges:

1. **Extreme Class Imbalance**: Only ~1.9% of pixels represent landslides
2. **Geographic Diversity**: Models must generalize across different terrains and climates
3. **Multi-Modal Data**: Requires processing 14 different spectral and topographic channels
4. **Subtle Features**: Landslides can be visually similar to natural terrain variations

---

## âœ¨ Key Features

- âœ… **Attention U-Net Architecture**: Advanced segmentation with attention mechanisms
- âœ… **Multi-Spectral Processing**: Handles 14-channel satellite imagery
- âœ… **Class Imbalance Handling**: Custom loss functions (Focal + Tversky)
- âœ… **Ensemble Prediction**: Combines multiple checkpoints for robustness
- âœ… **Comprehensive Evaluation**: Detailed metrics and visualizations
- âœ… **Google Colab Training**: GPU-accelerated training notebook included
- âœ… **Production-Ready Code**: Well-documented, modular architecture

---

## ğŸ“Š Dataset

### Landslide4Sense Dataset

This project uses satellite imagery from the **Landslide4Sense** competition.

**Dataset Statistics:**
- **Training Set**: 3,799 images + masks
- **Validation Set**: 245 images + masks
- **Test Set**: 800 images + masks
- **Image Size**: 128 Ã— 128 pixels
- **Channels**: 14 bands
  - **Bands 1-12**: Sentinel-2 multispectral data
  - **Band 13**: Slope (ALOS PALSAR)
  - **Band 14**: Digital Elevation Model (DEM, ALOS PALSAR)

**Class Distribution:**
- Background (non-landslide): ~98.1%
- Landslide: ~1.9%

> âš ï¸ **Note**: The dataset is NOT included in this repository due to size (~2.4 GB).  
> See [data/README.md](data/README.md) for download instructions.

### Data Preprocessing

1. **Normalization**:
   - Sentinel-2 bands: Percentile normalization (2nd-98th percentile)
   - Slope & DEM: Min-max normalization

2. **Augmentation** (training only):
   - Geometric: Flips, rotations, affine transformations
   - Noise: Gaussian noise, Gaussian blur
   - Intensity: Brightness/contrast adjustments
   - Deformation: Elastic transforms

---

## ğŸ—ï¸ Model Architecture

### Attention U-Net

The model uses an **Attention U-Net** architecture, which enhances the standard U-Net with attention gates for better feature selection.

**Architecture Highlights:**

```
Input: [Batch, 14, 128, 128]  # 14-channel satellite image
         â†“
Encoder Path:
  - Level 1: 64 channels  (128Ã—128)
  - Level 2: 128 channels (64Ã—64)
  - Level 3: 256 channels (32Ã—32)
  - Level 4: 512 channels (16Ã—16)
  - Bottleneck: 1024 channels (8Ã—8)
         â†“
Decoder Path (with Attention Gates):
  - Level 4: 512 channels (16Ã—16) + Attention
  - Level 3: 256 channels (32Ã—32) + Attention
  - Level 2: 128 channels (64Ã—64) + Attention
  - Level 1: 64 channels (128Ã—128) + Attention
         â†“
Output: [Batch, 2, 128, 128]  # 2-class segmentation (background, landslide)
```

**Model Size**: 34 million parameters

**Key Components:**
- **Attention Gates**: Highlight important features from skip connections
- **Dropout Regularization**: 30% dropout for better generalization
- **Batch Normalization**: Stabilizes training

### Loss Function

**Combined Loss** = 0.4 Ã— Focal Loss + 0.6 Ã— Tversky Loss

- **Focal Loss** (Î±=0.25, Î³=3.0): Focuses on hard examples
- **Tversky Loss** (Î±=0.2, Î²=0.8): Penalizes false negatives more than false positives

This combination effectively handles the extreme class imbalance.

---

## ğŸ“ˆ Results

### Performance Metrics

| Dataset    | F1 Score | Precision | Recall | Notes                          |
|------------|----------|-----------|--------|--------------------------------|
| Validation | 0.6594   | 0.5490    | 0.8256 | ValidData (245 images)         |
| **Test**   | **0.5963** | **0.5403** | **0.6652** | **TestData (800 images)** |

### Model Comparison

| Model                    | Test F1 | Improvement | Notes                |
|--------------------------|---------|-------------|----------------------|
| Baseline (competition)   | 0.5780  | -           | Reference baseline   |
| Standard U-Net           | 0.5901  | +2.1%       | Without attention    |
| Attention U-Net (single) | 0.5746  | -0.6%       | Single best checkpoint |
| **Attention U-Net (ensemble)** | **0.5963** | **+3.2%** | **Final model (3 checkpoints)** |

### Key Achievements

âœ… **Honest Metrics**: Eliminated data leakage, proper train/validation/test splits  
âœ… **Improved Generalization**: Reduced overfitting gap from 14% to 9.6%  
âœ… **State-of-the-Art Architecture**: Attention mechanisms for better feature learning  
âœ… **Robust Prediction**: Ensemble of 3 checkpoints for stable results  

## ğŸ“¸ Visualizations

### Performance Distribution

![Performance Distribution](visualizations/performance_distribution.png)

**Key Insights:**
- Mean F1: 0.596 (median: 0.612)
- 54% of images achieve F1 â‰¥ 0.6
- 14% achieve excellent F1 â‰¥ 0.8
- Performance varies by landslide size and terrain complexity

### Example Predictions

#### âœ… Successful Detection (F1 > 0.90)

| Image 152 (F1: 0.926) | Image 432 (F1: 0.924) |
|:---------------------:|:---------------------:|
| ![](visualizations/prediction_image_152.png) | ![](visualizations/prediction_image_432.png) |

**Success factors:**
- Large, clearly defined landslides
- High spectral contrast with background
- Minimal vegetation cover
- Simple terrain

#### âš ï¸ Challenging Cases (F1 = 0)

| Image 100 | Image 101 |
|:---------:|:---------:|
| ![](visualizations/prediction_image_100.png) | ![](visualizations/prediction_image_101.png) |

**Note:** F1 = 0 indicates **no landslides present** in ground truth (true negatives).  
These are not model failures - the model correctly predicted background.

#### ğŸ“Š Confusion Matrix Examples

![Confusion Matrix Grid](visualizations/confusion_matrix_grid.png)

**Color coding:**
- ğŸŸ¢ Green: Ground truth landslides
- ğŸ”´ Red: Model predictions
- Overlap areas: True positives (correct detections)

**Categories:**
- **TP (True Positive)**: Correct landslide detection
- **FP (False Positive)**: False alarm (predicted landslide where none exists)
- **FN (False Negative)**: Missed landslide
- **TN (True Negative)**: Correct background prediction

For more visualizations, see the [`visualizations/`](visualizations/) directory.

---

## ğŸš€ Installation

### Prerequisites

- Python 3.12 (recommended) or 3.11+
- NVIDIA GPU with CUDA 11.8 (optional, for training)
- 16 GB RAM minimum (8 GB for inference only)

### Setup Instructions

#### 1. Clone the Repository

```bash
git clone https://github.com/Oghuz20/Landslide-Detection-Satellite-AI.git
cd Landslide-Detection-Satellite-AI
```

#### 2. Create Virtual Environment

**Windows (PowerShell):**
```powershell
python -m venv venv_landslide
.\venv_landslide\Scripts\Activate.ps1
```

**Linux/Mac:**
```bash
python3 -m venv venv_landslide
source venv_landslide/bin/activate
```

#### 3. Install Dependencies

**Windows:**
```powershell
pip install -r requirements.txt --break-system-packages
```

**Linux/Mac:**
```bash
pip install -r requirements.txt
```

#### 4. Download Dataset

See [data/README.md](data/README.md) for dataset download instructions.

Place the downloaded data in the `data/` folder:
```
data/
â”œâ”€â”€ TrainData/
â”œâ”€â”€ ValidData/
â””â”€â”€ TestData/
```

#### 5. Verify Installation

```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA Available: {torch.cuda.is_available()}')"
```

---

## ğŸ’» Usage

### Quick Start: Inference

Run predictions on test data using the ensemble model:

```bash
python ensemble_predict.py
```

**Output**: Predictions saved to `predictions/test_final/`

### Training (Google Colab)

The model was trained on Google Colab with free T4 GPU:

1. Open [`notebooks/train_colab.ipynb`](notebooks/train_colab.ipynb) in Google Colab
2. Upload your dataset or mount Google Drive
3. Run all cells
4. Download trained checkpoints

**Training Configuration:**
- **Optimizer**: AdamW (lr=1e-4, weight_decay=2e-4)
- **Batch Size**: 16
- **Epochs**: 40 (early stopping at epoch 37)
- **Best Checkpoint**: Epoch 25 (Validation F1: 0.6594)

### Evaluation

Evaluate model performance on test set:

```bash
python src/evaluate.py
```

**Output**: Metrics printed to console and saved to `evaluation_results.txt`

### Visualization

Generate comprehensive visualizations:

```bash
python src/visualize.py
```

**Output**: Visualizations saved to `visualizations/`:
- Performance distribution plots
- Confusion matrix examples
- Best/worst case predictions
- Random sample predictions

### Example Code

```python
from src.dataset import LandslideDataset, get_valid_transforms
from src.model import create_model
import torch

# Load model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = create_model('attention_unet', n_channels=14, n_classes=2)
model.load_state_dict(torch.load('checkpoints/best_model.pth', map_location=device))
model.to(device)
model.eval()

# Load data
dataset = LandslideDataset(
    data_dir='./data',
    split='test',
    transform=get_valid_transforms()
)

# Make prediction
sample = dataset[0]
image = sample['image'].unsqueeze(0).to(device)

with torch.no_grad():
    output = model(image)
    prediction = torch.argmax(output, dim=1).cpu().numpy()

print(f"Prediction shape: {prediction.shape}")
```

---

## ğŸ“ Project Structure

```
Landslide-Detection-Satellite-AI/
â”‚
â”œâ”€â”€ ğŸ“ data/                     # Dataset (not in Git)
â”‚   â”œâ”€â”€ TrainData/               # 3,799 training images + masks
â”‚   â”œâ”€â”€ ValidData/               # 245 validation images + masks
â”‚   â”œâ”€â”€ TestData/                # 800 test images + masks
â”‚   â””â”€â”€ README.md                # Download instructions
â”‚
â”œâ”€â”€ ğŸ“ src/                      # Source code
â”‚   â”œâ”€â”€ __init__.py              # Package initialization
â”‚   â”œâ”€â”€ dataset.py               # Data loading and preprocessing
â”‚   â”œâ”€â”€ model.py                 # Attention U-Net architecture
â”‚   â”œâ”€â”€ evaluate.py              # Evaluation metrics
â”‚   â””â”€â”€ visualize.py             # Visualization functions
â”‚
â”œâ”€â”€ ğŸ“ checkpoints/              # Trained models
â”‚   â”œâ”€â”€ best_model.pth           # Best model (Epoch 25, F1=0.6594)
â”‚   â”œâ”€â”€ epoch_30.pth             # Checkpoint for ensemble
â”‚   â”œâ”€â”€ epoch_35.pth             # Checkpoint for ensemble
â”‚   â””â”€â”€ training_history.png     # Training curves
â”‚
â”œâ”€â”€ ğŸ“ predictions/              # Model outputs
â”‚   â””â”€â”€ test_final/              # Test set predictions (800 masks)
â”‚
â”œâ”€â”€ ğŸ“ visualizations/           # Result visualizations
â”‚   â”œâ”€â”€ performance_distribution.png
â”‚   â”œâ”€â”€ confusion_matrix_grid.png
â”‚   â””â”€â”€ prediction_*.png         # Individual predictions
â”‚
â”œâ”€â”€ ğŸ“ docs/                     # Documentation
â”‚   â”œâ”€â”€ RESULTS.md               # Detailed results analysis
â”‚   â”œâ”€â”€ METHODOLOGY.md           # Training methodology
â”‚   â”œâ”€â”€ USAGE.md                 # Usage examples
â”‚   â””â”€â”€ final_results.txt        # Raw metrics
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                # Jupyter notebooks
â”‚   â””â”€â”€ train_colab.ipynb        # Google Colab training notebook
â”‚
â”œâ”€â”€ ensemble_predict.py          # Main inference script
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .gitignore                   # Git ignore rules
â”œâ”€â”€ LICENSE                      # MIT License
â””â”€â”€ README.md                    # This file
```

---

## ğŸ“š Documentation

Detailed documentation available in the [`docs/`](docs/) folder:

- **[RESULTS.md](docs/RESULTS.md)**: Comprehensive results analysis
  - Confusion matrices
  - Performance comparisons
  - Error analysis
  - Geographic distribution of errors

- **[METHODOLOGY.md](docs/METHODOLOGY.md)**: Training methodology
  - Data preparation
  - Model architecture details
  - Loss function design
  - Hyperparameter tuning

- **[USAGE.md](docs/USAGE.md)**: Detailed usage examples
  - Custom dataset preparation
  - Advanced training options
  - Visualization customization
  - Deployment guidelines

---

## ğŸ“ Academic Context

This project was developed as a **graduation thesis** on automated landslide detection using deep learning. The work demonstrates:

1. **Problem Definition**: Addressing the challenge of landslide detection at scale
2. **Literature Review**: State-of-the-art semantic segmentation techniques
3. **Methodology**: Attention U-Net with specialized loss functions
4. **Experimentation**: Systematic evaluation of different architectures and techniques
5. **Results Analysis**: Honest reporting of performance and limitations
6. **Practical Application**: Production-ready code for real-world deployment

### Limitations & Future Work

**Current Limitations:**
- Geographic domain shift between validation and test sets (9.6% performance gap)
- Small validation set (245 images) limits hyperparameter optimization
- Extreme class imbalance remains challenging

**Future Improvements:**
- Collect more diverse validation data from test regions
- Explore transformer-based architectures (SegFormer, Mask2Former)
- Implement semi-supervised learning with unlabeled data
- Multi-task learning (landslide + landslide type classification)
- Real-time deployment on satellite data streams

---

## ğŸ“– Citation

If you use this code or model in your research, please cite:

```bibtex
@software{landslide_detection_2026,
  author = {[Your Name]},
  title = {Landslide Detection from Satellite Imagery using Attention U-Net},
  year = {2026},
  url = {https://github.com/Oghuz20/Landslide-Detection-Satellite-AI}
}
```

**Dataset Citation:**

```bibtex
@article{ghorbanzadeh2022landslide4sense,
  title={The outcome of the 2022 landslide4sense competition: Advanced landslide detection from multisource satellite imagery},
  author={Ghorbanzadeh, Omid and Xu, Yonghao and Ghamisi, Pedram and Kopp, Martin and Kreil, David},
  journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  year={2022},
  publisher={IEEE}
}
```

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Landslide4Sense Competition** for providing the dataset
- **Google Colab** for free GPU resources
- **PyTorch** and **Albumentations** communities for excellent libraries
- Thesis advisor and committee for guidance

---

## ğŸ“¬ Contact

For questions, issues, or collaborations:

- **GitHub Issues**: [Open an issue](https://github.com/Oghuz20/Landslide-Detection-Satellite-AI/issues)
- **Email**: [your.email@example.com]
- **LinkedIn**: [Your LinkedIn Profile]

---

## â­ Star History

If you find this project helpful, please consider giving it a â­!

[![Star History Chart](https://api.star-history.com/svg?repos=Oghuz20/Landslide-Detection-Satellite-AI&type=Date)](https://star-history.com/#Oghuz20/Landslide-Detection-Satellite-AI&Date)

---

**Made with â¤ï¸ for landslide detection research**
